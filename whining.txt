Hi, 
For question 13 and 14, we are a little bit confused as to what the expectations are. For q13, you state that as the model trains over 50 000 batches, we should show the tradeoff of decreasing validation loss and that samples begin to look less random. This sets an expectation that the model should improve for every 10 000 batch up until its best result at 50 000. However,  the model converges very quickly, around 500 batches, and a strong overfitting. Could this be expected because of the toy dataset? Our Autoregressive model does have some regularization with two dropout layers. 

For q14 we interpreted the question as do some experiment (modify/add to q13) where you try to achieve better results. However it does state to do a full training run, does that mean to run over 50 000 batches? We implemented rotary embeddings to enhance the model and some features to mitigate the overfitting, for example with early stopping. But with early stopping it concludes training long before 50 000 epochs as the model still have an overfitting trend. 